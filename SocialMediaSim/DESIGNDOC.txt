ASSIGNMENT-4 REPORT


Group number- 16
Abothula Suneetha 20CS10004
Manami Mondal 20CS10033
Priyanshi Dixit 20CS10047
Pranil Dey 20CS30038

DATA STRUCTURES USED:


struct Edge
{
        int src;
        int dest;
}; 
Edges of graph by struct Edge having a source connecting to a destination.


struct User
{
        int node_id;
        int degree;
        queue<Action> wall_queue;
        FeedQueue feed_queue;
        int priority = 1; // 0 for priority, 1 for chronological
        int like_count = 0;
        int post_count = 0;
        int comment_count = 0;
};
Every node(User) has a node_id, degree, wall_queue(for actions generated by it), feed_queue(for actions generated by its neighbours), counters for all the three types of actions and priority(0 for priority and 1 for chronological)


struct Action
{
        int user_id;             // node id who did the action
        int action_id;           // counter variable associated with each node and specific to each action
        string action_type;  // action type (post, comment, like)
        long long timestamp; // unix timestamp of generating the action
        // Constructor to initialise the fields
        Action(int user_id, int action_id, string action_type, long long timestamp) : user_id(user_id), action_id(action_id), action_type(action_type), timestamp(timestamp) {}
};
Every Action has a user_id which is the node_id of the poster, action_id which is the count of the action_type, timestamp.

typedef struct FeedQueueNode
{
        Action action;
        struct FeedQueueNode *next;
} FeedQueueNode;
It has an Action element that is being stored in the node and a pointer to the next node in the queue. 


typedef struct FeedQueue
{
        FeedQueueNode *head;
        FeedQueueNode *tail;
        pthread_mutex_t lock;
} FeedQueue;
It has  pointers to the first and last nodes in the queue and a mutex lock to protect access to the queue.
So, it holds Action elements where each element is stored in a FeedQueueNode.


queue<Action> push_queue;
This stores the actions generated by the userSimulator thread that are to be added to the feed queues of neighbours of the poster node.


int update_queue[MAX_NODES];
To store the IDs of nodes whose feed queues have been updated. Whenever an action is added to a node's feed queue, its ID is added to the update queue. So, the readPost threads can check this update queue for IDs of nodes whose feed queues have been updated, and only process those nodes' feed queues.

DETAILS ABOUT SIZES OF DIFFERENT QUEUES , ARRAYS , VECTORS , MAPS:


1. push_queue : queue in which actions generated by userSimulator are pushed to be monitored by pushUpdate threads. Since the number of actions depends on the graph and the nodes’ degree itself maximum size can’t be pre-assumed. Also STL provides a feature of declaration without max_size . Hence use of  queue<Action> push_queue


2. wall_queue : queue in which actions generated by node itself are pushed .Each action has a data structure ‘Action’. Since the number of self-generated actions depend on the graph and the nodes’ degree, maximum size can’t be pre-assumed. Also STL provides a feature of declaration without max_size . Hence use of  queue<Action> wall_queue


3. feed_queue : queue in which actions generated by neighbours of a particular node itself are pushed. It has 2 pointers , head and tail and 1 mutex lock for the purpose of ensuring that extraction takes place after insertion. Each feed_queue Node ‘FeedQueueNode’ has an action associated with it and a pointer to the next node (like a linked list). Since it is a struct as and when new actions are present in ‘push_queue’ , new nodes of ‘FeedQueueNode’ are created using malloc. No specification of max_sizes are needed here. Hence use of  FeedQueue feed_queue


4. update_queue :  array containing the node_id of nodes whose feed_queue has recently been changed. It has an ‘update_queue_tail’ and ‘update_queue_head’  counter for the last  and first node index. Since MAX_NODES=37700 information already provided in the problem statement so the number of nodes can never be > MAX_NODES . Hence use of  int update_queue[MAX_NODES] 


5. users : each node of a graph is described by this structure.Since MAX_NODES=37700 already provided to us . Hence use of  vector<User> users(MAX_NODES)


6. adj_list : unordered_map for storing neighbour id’s for a particular node. MAX_NODES is already known so map max size is MAX_NODES and the max number of neighbours of a node can be MAX_NODES -1 . Hence use of 
unordered_map<int, vector<int>> adj_list(MAX_NODES)

LOCKS USED:


1. update_mutex: To protect the access to the push_queue which is accessed by userSimulator and pushUpdate threads. After adding to the push_queue, the userSimulator uses pthread_cond_broadcast to unblock the waiting threads i.e., the push threads that are waiting on condition variable update_cv. 


userSimulator : 
 pthread_mutex_lock(&update_mutex);
             // accessing push_queue
             pthread_cond_broadcast(&update_cv);
             pthread_mutex_unlock(&update_mutex);


pushUpdate: 
pthread_mutex_lock(&update_mutex);         
            while (push_queue.empty())
            {
                pthread_cond_wait(&update_cv, &update_mutex);
            }
            // accessing push_queue
            pthread_mutex_unlock(&update_mutex);

2. feed_queue.lock: To ensure the access of the feed_queues that are being shared by pushUpdate threads that are writing the actions to the feed queues and readPost threads that are reading and removing the actions from feed queues.


pushUpdate:
pthread_mutex_lock(&users[nid].feed_queue.lock);
            // accessing update_queue
pthread_cond_broadcast(&users[nid].feed_queue.cond);
pthread_mutex_unlock(&users[nid].feed_queue.lock);


readPost:
pthread_mutex_lock(&users[user_id].feed_queue.lock);
// accessing feed_queue
pthread_mutex_unlock(&users[user_id].feed_queue.lock);

3. update_queue_lock: To protect the access to the update_queue that is being accessed by pushUpdate to write the ids of the nodes whose feed queues are being updated and readPost threads to monitor the nodes whose feed queues are being changed.


pushUpdate:
pthread_mutex_lock(&update_queue_lock);
// accessing update_queue                
                pthread_cond_broadcast(&update_queue_cond);
pthread_mutex_unlock(&update_queue_lock);


readPost:
pthread_mutex_lock(&update_queue_lock);


while (update_queue_head == update_queue_tail)
{
     pthread_cond_wait(&update_queue_cond, &update_queue_lock);
 }
// accessing update_queue
pthread_mutex_unlock(&update_queue_lock);

4. lock: This is to ensure proper writing to the log file by all the threads that are printing their corresponding actions.

Concurrency is preserved throughout the code particularly by the below mentioned threads:
1. void *userSimulator(void *arg) Multiple threads can generate 100 random nodes and calculate the number of actions and Actions are constructed(though the problem statement mentioned one userSimulator thread) . Only when we are pushing in the push_queue do we want mutual exclusion for access of push_queue.push(action).
Another lock is used for avoiding overwriting of log file which is immediately unlock when logfile write is over
2. void *pushUpdate(void *arg) Different threads can simultaneously . For example one thread might execute push_queue.pop() by locking the update_mutex while other thread would add nid to the feed_queue of node_id by pthread_mutex_lock
(&users[nid].feed_queue.lock). Others might be able to access the log file as well These factors aid in concurrency of threads and not having a single execution thread
void *readPost(void *arg) This also ensures concurrency of threads by ensuring that some thread might access the user_id in the update_queue .If not it can go to reading action of different priority and some might write to sns.log